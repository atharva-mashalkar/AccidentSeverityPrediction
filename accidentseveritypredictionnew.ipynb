{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Issues faced:\n* The size of the data set is very large\n* The data is very unbalanced","metadata":{}},{"cell_type":"markdown","source":"# Importing necessary libraries","metadata":{}},{"cell_type":"code","source":"# Importing data processing libraries\nimport math\nimport numpy as np\nfrom numpy import log\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nimport category_encoders as ce\nfrom category_encoders.binary import BinaryEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import FeatureUnion\nimport csv\nfrom collections import Counter\nfrom imblearn.over_sampling import SMOTE\nimport time\nfrom nltk.corpus import stopwords\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.model_selection import RepeatedStratifiedKFold\n\n# Importing data visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Model libraries \nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\nfrom sklearn.naive_bayes import CategoricalNB, BernoulliNB, MultinomialNB, GaussianNB\nimport xgboost\n\n# Model evaluation \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_curve\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\n\n# Hyperparameter tunning libraries\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\nimport random\n","metadata":{"execution":{"iopub.status.busy":"2021-07-19T02:49:46.64731Z","iopub.execute_input":"2021-07-19T02:49:46.647836Z","iopub.status.idle":"2021-07-19T02:49:49.293685Z","shell.execute_reply.started":"2021-07-19T02:49:46.647797Z","shell.execute_reply":"2021-07-19T02:49:49.292829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Data","metadata":{}},{"cell_type":"code","source":"# Function to import dataset\ndef importData():\n    data = pd.read_csv(\"../input/us-accidents/US_Accidents_Dec20_Updated.csv\")\n    split = StratifiedShuffleSplit(n_splits=1, test_size = 0.2, random_state = 21)\n    for train_index, test_index in split.split(data, data[\"Severity\"]):\n        train = data.loc[train_index]\n        test = data.loc[test_index]\n    return [train, test]","metadata":{"execution":{"iopub.status.busy":"2021-07-19T02:49:49.294899Z","iopub.execute_input":"2021-07-19T02:49:49.295308Z","iopub.status.idle":"2021-07-19T02:49:49.300283Z","shell.execute_reply.started":"2021-07-19T02:49:49.295279Z","shell.execute_reply":"2021-07-19T02:49:49.299618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stitified splitting the data\ntrain, test = importData()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T02:49:49.301897Z","iopub.execute_input":"2021-07-19T02:49:49.302269Z","iopub.status.idle":"2021-07-19T02:50:47.813329Z","shell.execute_reply.started":"2021-07-19T02:49:49.302241Z","shell.execute_reply":"2021-07-19T02:50:47.812234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T02:50:47.815159Z","iopub.execute_input":"2021-07-19T02:50:47.815584Z","iopub.status.idle":"2021-07-19T02:50:47.838342Z","shell.execute_reply.started":"2021-07-19T02:50:47.815539Z","shell.execute_reply":"2021-07-19T02:50:47.837566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T02:50:47.839359Z","iopub.execute_input":"2021-07-19T02:50:47.839766Z","iopub.status.idle":"2021-07-19T02:50:49.408753Z","shell.execute_reply.started":"2021-07-19T02:50:47.839737Z","shell.execute_reply":"2021-07-19T02:50:49.40775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Taking a quick look into the data","metadata":{}},{"cell_type":"code","source":"# train.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:41:20.561391Z","iopub.execute_input":"2021-07-16T07:41:20.562221Z","iopub.status.idle":"2021-07-16T07:41:20.571711Z","shell.execute_reply.started":"2021-07-16T07:41:20.562165Z","shell.execute_reply":"2021-07-16T07:41:20.570475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# n = len(train[\"Severity\"])\n# classes = [(clas,float(count)) for clas,count in Counter(train[\"Severity\"]).items()]\n# k = len(classes)\n\n# H = -sum([ (count/n) * log((count/n)) for clas,count in classes]) #Shannon entropy\n\n# print(H/log(k))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:41:20.573603Z","iopub.execute_input":"2021-07-16T07:41:20.574162Z","iopub.status.idle":"2021-07-16T07:41:20.586651Z","shell.execute_reply.started":"2021-07-16T07:41:20.574111Z","shell.execute_reply":"2021-07-16T07:41:20.585421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Data is very imbalanced***","metadata":{}},{"cell_type":"markdown","source":"# Visualizing Imbalance","metadata":{}},{"cell_type":"code","source":"# severity_counts = train[\"Severity\"].value_counts()\n\n# plt.figure(figsize=(10, 8))\n# plt.title(\"Histogram for the severity\")\n# sns.barplot(x = severity_counts.index,y = severity_counts.values)\n# sns.set(style=\"darkgrid\")\n# sns.set_context(\"talk\")\n# plt.xlabel(\"Severity\")\n# plt.ylabel(\"Number of Accidents\")\n# plt.show()\n# print(severity_counts)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:41:20.588054Z","iopub.execute_input":"2021-07-16T07:41:20.588447Z","iopub.status.idle":"2021-07-16T07:41:20.60524Z","shell.execute_reply.started":"2021-07-16T07:41:20.588413Z","shell.execute_reply":"2021-07-16T07:41:20.603861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking correlation","metadata":{}},{"cell_type":"code","source":"# corr_matrix = train.corr()\n\n# plt.figure(figsize=(12, 12))\n# sns.heatmap(corr_matrix, vmin=-1, vmax=1, cmap=\"seismic\")\n# plt.gca().patch.set(hatch=\"X\", edgecolor=\"#0080ff\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:41:20.606565Z","iopub.execute_input":"2021-07-16T07:41:20.606982Z","iopub.status.idle":"2021-07-16T07:41:20.623249Z","shell.execute_reply.started":"2021-07-16T07:41:20.606949Z","shell.execute_reply":"2021-07-16T07:41:20.621953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Few very highly correlated features are***\n* Start_Lat and End_Lat\n* Start_Lng and End_Lng\n* Start_Lng and End_Lng with Temperature and WindChill\n* Temperature and Wind_Chill\n* Humidity with Temperature and Wind_Chill\n* Visibility and Humidity\n* Traffic_Signal and Crossing\n* Traffic_Calming and Bump","metadata":{}},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# train.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:41:20.626122Z","iopub.execute_input":"2021-07-16T07:41:20.626514Z","iopub.status.idle":"2021-07-16T07:41:20.638665Z","shell.execute_reply.started":"2021-07-16T07:41:20.626482Z","shell.execute_reply":"2021-07-16T07:41:20.637333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dropping Few Features\n* ID\n* End_Lat\n* End_Lng\n* Description\n* Weather_Timestamp\n* Country","metadata":{}},{"cell_type":"code","source":"class dropCompletelyUnnecessaryFeatures(BaseEstimator, TransformerMixin):\n    def __init__(self,arg=None):\n        self.features = arg\n    def fit(self,X,y=None):\n        return self\n    def transform(self,data,y=None):\n        features = list(data.columns.values) if self.features == None else self.features\n        data.drop(features, axis = 1, inplace = True)\n        return data\n    \n# temp = dropCompletelyUnnecessaryFeatures(['ID', 'End_Lat','End_Lng', 'Description','Weather_Timestamp','Country'])\n# temp.transform(train)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:41:20.641182Z","iopub.execute_input":"2021-07-16T07:41:20.641646Z","iopub.status.idle":"2021-07-16T07:41:20.654832Z","shell.execute_reply.started":"2021-07-16T07:41:20.641602Z","shell.execute_reply":"2021-07-16T07:41:20.65349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Converting Start_Time and End_Time from object to float/int","metadata":{}},{"cell_type":"code","source":"class convertStartAndEndTime(BaseEstimator, TransformerMixin):\n    def __init__(self,arg=None):\n        self.arg = arg\n    def fit(self,X,y=None):\n        return self\n    def transform(self,df,y=None):\n        # Cast Start_Time to datetime\n        df[\"Start_Time\"] = pd.to_datetime(df[\"Start_Time\"])\n        df[\"End_Time\"] = pd.to_datetime(df[\"End_Time\"])\n        # Extract year, month, weekday, day, hour and minute\n        df[\"Year\"] = df[\"Start_Time\"].dt.year\n        df[\"Month\"] = df[\"Start_Time\"].dt.month\n        df[\"Weekday\"] = df[\"Start_Time\"].dt.weekday\n        df[\"Day\"] = df[\"Start_Time\"].dt.day\n        df[\"Hour\"] = df[\"Start_Time\"].dt.hour\n        df[\"Minute\"] = df[\"Start_Time\"].dt.minute\n        df[\"Duration\"] = df[\"End_Time\"] - df[\"Start_Time\"]\n        df[\"Duration\"] = df[\"Duration\"].dt.total_seconds()\n        df.drop(['End_Time',\"Start_Time\"], axis = 1, inplace = True)\n        return df\n    \n# temp = convertStartAndEndTime()\n# temp.transform(train)\n# train.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:41:20.6572Z","iopub.execute_input":"2021-07-16T07:41:20.657871Z","iopub.status.idle":"2021-07-16T07:41:20.670264Z","shell.execute_reply.started":"2021-07-16T07:41:20.657704Z","shell.execute_reply":"2021-07-16T07:41:20.669217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Finding unique entries","metadata":{}},{"cell_type":"code","source":"# categorical_features = set(['Sunrise_Sunset','Civil_Twilight','Nautical_Twilight','Astronomical_Twilight','Weather_Condition',\n#                            'Wind_Direction','Street','State','Side','City','County','Zipcode','Timezone','Airport_Code'])\n\n# for cat in categorical_features:\n#     train[cat] = train[cat].astype(\"category\")\n\n# train.info()\n\n# print(\"\\nUnique classes for each categorical feature:\")\n# for cat in categorical_features:\n#     print(\"{:15s}\".format(cat), \"\\t\", len(train[cat].unique()))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:41:20.671552Z","iopub.execute_input":"2021-07-16T07:41:20.672205Z","iopub.status.idle":"2021-07-16T07:41:20.69182Z","shell.execute_reply.started":"2021-07-16T07:41:20.672147Z","shell.execute_reply":"2021-07-16T07:41:20.690078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking missing entries","metadata":{}},{"cell_type":"code","source":"# train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:41:20.693256Z","iopub.execute_input":"2021-07-16T07:41:20.693632Z","iopub.status.idle":"2021-07-16T07:41:20.707644Z","shell.execute_reply.started":"2021-07-16T07:41:20.693557Z","shell.execute_reply":"2021-07-16T07:41:20.706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dropping a few features \n* County, State, Zipcode, Timezone, Airport_Code, Street. (As we are just keeping the record \"City\" wise)\n* Number and Precipitation (As they contain many  missing entries)\n* Wind_Chill (As it contains many missing entries and is highly correlated with Temperature)","metadata":{}},{"cell_type":"code","source":"class dropFewMoreFeatures(BaseEstimator, TransformerMixin):\n    def __init__(self,arg=None):\n        self.features = arg\n    def fit(self,X,y=None):\n        return self\n    def transform(self,data,y=None):\n        features = list(data.columns.values) if self.features == None else self.features\n        data.drop(features, axis = 1, inplace = True)\n        return data\n    \n# temp = dropFewMoreFeatures(['County', 'State','Zipcode', 'Timezone','Airport_Code','Street', 'Number', 'Precipitation(in)','Wind_Chill(F)'])\n# temp.transform(train)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:41:20.709998Z","iopub.execute_input":"2021-07-16T07:41:20.710476Z","iopub.status.idle":"2021-07-16T07:41:20.723135Z","shell.execute_reply.started":"2021-07-16T07:41:20.710442Z","shell.execute_reply":"2021-07-16T07:41:20.722228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:41:20.724479Z","iopub.execute_input":"2021-07-16T07:41:20.725186Z","iopub.status.idle":"2021-07-16T07:41:20.742307Z","shell.execute_reply.started":"2021-07-16T07:41:20.725136Z","shell.execute_reply":"2021-07-16T07:41:20.740499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***As the continuous features with missing values do not have much variance, we can use mean as a measure to fill their missing values. We will drop entries of categorical variables having missing values***","metadata":{}},{"cell_type":"markdown","source":"# Filling missing values","metadata":{}},{"cell_type":"code","source":"class fillNA(BaseEstimator, TransformerMixin):\n    def __init__(self, arg = None):\n        self.featuresToFill = arg\n    def fit(self,X,y=None):\n        return self\n    def transform(self,X,y = None):\n        X[self.featuresToFill] = X[self.featuresToFill].fillna(X[self.featuresToFill].mean())\n        X.dropna(inplace = True)\n        return X\n\n# temp = fillNA(['Temperature(F)','Humidity(%)','Pressure(in)','Visibility(mi)','Wind_Speed(mph)'])\n# temp.transform(train)\n# train.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:41:20.743986Z","iopub.execute_input":"2021-07-16T07:41:20.744538Z","iopub.status.idle":"2021-07-16T07:41:20.757562Z","shell.execute_reply.started":"2021-07-16T07:41:20.744487Z","shell.execute_reply":"2021-07-16T07:41:20.756002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:41:20.75994Z","iopub.execute_input":"2021-07-16T07:41:20.760827Z","iopub.status.idle":"2021-07-16T07:41:20.773557Z","shell.execute_reply.started":"2021-07-16T07:41:20.76075Z","shell.execute_reply":"2021-07-16T07:41:20.772117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Class for replacing boolean values","metadata":{}},{"cell_type":"code","source":"class replaceBoolean(BaseEstimator, TransformerMixin):\n    def __init__(self,arg=None):\n        self.features = arg\n    def fit(self,X,y=None):\n        return self\n    def transform(self,X,y=None):\n        features = list(X.columns.values) if self.features == None else self.features\n        for feature in features:\n            X.loc[X[feature] == True, feature] = 1\n            X.loc[X[feature] == False, feature] = 0\n        return X","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:41:20.775223Z","iopub.execute_input":"2021-07-16T07:41:20.775822Z","iopub.status.idle":"2021-07-16T07:41:20.789281Z","shell.execute_reply.started":"2021-07-16T07:41:20.775782Z","shell.execute_reply":"2021-07-16T07:41:20.787219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating a preprocessing pipeline","metadata":{}},{"cell_type":"code","source":"class FeatureSelector(BaseEstimator, TransformerMixin):\n    \"\"\"Select only specified columns.\"\"\"\n    def __init__(self, columns):\n        self.columns = columns\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        return X[self.columns]","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:41:20.791152Z","iopub.execute_input":"2021-07-16T07:41:20.791545Z","iopub.status.idle":"2021-07-16T07:41:20.801868Z","shell.execute_reply.started":"2021-07-16T07:41:20.791511Z","shell.execute_reply":"2021-07-16T07:41:20.800711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessData():\n    \n    data = pd.read_csv(\"../input/us-accidents/US_Accidents_Dec20_Updated.csv\")\n    \n    def customTransforms(data):\n        temp = dropCompletelyUnnecessaryFeatures(['ID', 'End_Lat','End_Lng', 'Description','Weather_Timestamp','Country'])\n        data = temp.transform(data)\n        temp = convertStartAndEndTime()\n        data = temp.transform(data)\n        temp = dropFewMoreFeatures(['County', 'State','Zipcode', 'Timezone','Airport_Code','Street', 'Number', 'Precipitation(in)','Wind_Chill(F)'])\n        data = temp.transform(data)\n        temp = fillNA(['Temperature(F)','Humidity(%)','Pressure(in)','Visibility(mi)','Wind_Speed(mph)'])\n        data = temp.transform(data)\n        temp = replaceBoolean(['Amenity','Bump','Crossing','Give_Way','Junction','No_Exit','Railway','Roundabout','Station','Stop','Traffic_Calming','Traffic_Signal','Turning_Loop'])\n        data = temp.transform(data)\n        data.drop_duplicates(inplace=True)\n        return data\n    \n    finalChangesPipeine = ColumnTransformer([\n        ('binary_encoder', BinaryEncoder(cols = ['City','Wind_Direction','Weather_Condition'], return_df=True),['City','Wind_Direction','Weather_Condition']),\n        ('one_hot_encoder',ce.OneHotEncoder(),['Sunrise_Sunset','Civil_Twilight','Nautical_Twilight','Astronomical_Twilight','Side']),\n        ('scalar', StandardScaler(),['Start_Lat','Start_Lng','Distance(mi)','Temperature(F)','Humidity(%)','Pressure(in)','Visibility(mi)','Wind_Speed(mph)','Duration','Month','Weekday','Day','Hour','Minute','Year']),\n    ],n_jobs = 1, verbose = True, remainder='passthrough')\n    \n    data = customTransforms(data)\n    \n    y = data[\"Severity\"].tolist()\n    data.drop(\"Severity\", axis = 1, inplace = True)\n    \n    data = finalChangesPipeine.fit_transform(data)\n    \n    data = pd.DataFrame(data, columns = [x for x in range(1,len(data[0])+1)])\n    data = data.astype(dtype = np.float32)\n    \n    data[\"Severity\"] = y\n    split = StratifiedShuffleSplit(n_splits=1, test_size = 0.2, random_state = 21)\n    for train_index, test_index in split.split(data, data[\"Severity\"]):\n        train = data.loc[train_index]\n        test = data.loc[test_index]\n    return [train, test]\n\ntrain, test = preprocessData()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:41:20.803302Z","iopub.execute_input":"2021-07-16T07:41:20.803859Z","iopub.status.idle":"2021-07-16T07:43:30.470337Z","shell.execute_reply.started":"2021-07-16T07:41:20.803811Z","shell.execute_reply":"2021-07-16T07:43:30.469382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trying different models","metadata":{}},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"rnf_clf = RandomForestClassifier(max_depth= 192, max_features=29, n_estimators=211)\n# 0.8422375933500217\n\n#Output\n# Training Accuracy RandomForestClassifier 0.9990186502845451\n# F1-Score for Training RandomForestClassifier 0.9990149141866291\n# Classification Report for Training RandomForestClassifier               precision    recall  f1-score   support\n\n#            1       1.00      1.00      1.00     16834\n#            2       1.00      1.00      1.00   1247437\n#            3       1.00      1.00      1.00    388821\n#            4       1.00      0.98      0.99     71064\n\n#     accuracy                           1.00   1724156\n#    macro avg       1.00      0.99      1.00   1724156\n# weighted avg       1.00      1.00      1.00   1724156\n\n# Validation Accuracy RandomForestClassifier 0.8318067928730513\n# F1-Score for Validation RandomForestClassifier 0.8200637863625027\n# Classification Report for Validation RandomForestClassifier               precision    recall  f1-score   support\n\n#            1       0.84      0.49      0.62      4209\n#            2       0.85      0.95      0.89    311860\n#            3       0.76      0.56      0.64     97205\n#            4       0.75      0.40      0.52     17766\n\n#     accuracy                           0.83    431040\n#    macro avg       0.80      0.60      0.67    431040\n# weighted avg       0.82      0.83      0.82    431040","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:43:30.471625Z","iopub.execute_input":"2021-07-16T07:43:30.471929Z","iopub.status.idle":"2021-07-16T07:43:30.477177Z","shell.execute_reply.started":"2021-07-16T07:43:30.471901Z","shell.execute_reply":"2021-07-16T07:43:30.476166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extra Trees Classifier","metadata":{}},{"cell_type":"code","source":"ext_clf = ExtraTreesClassifier()\n\n#Output\n# Training Accuracy ExtraTreesClassifier 0.999025610211605\n# F1-Score for Training ExtraTreesClassifier 0.9990205684096188\n# Classification Report for Training               precision    recall  f1-score   support\n\n#            1       1.00      1.00      1.00     16834\n#            2       1.00      1.00      1.00   1247437\n#            3       1.00      1.00      1.00    388821\n#            4       1.00      0.98      0.99     71064\n\n#     accuracy                           1.00   1724156\n#    macro avg       1.00      0.99      1.00   1724156\n# weighted avg       1.00      1.00      1.00   1724156\n\n# Validation Accuracy ExtraTreesClassifier 0.7990209725315516\n# F1-Score for Validation ExtraTreesClassifier 0.7793423318222337\n# Classification Report for Validation               precision    recall  f1-score   support\n\n#            1       0.78      0.43      0.55      4209\n#            2       0.82      0.94      0.87    311860\n#            3       0.70      0.46      0.56     97205\n#            4       0.75      0.25      0.38     17766\n\n#     accuracy                           0.80    431040\n#    macro avg       0.76      0.52      0.59    431040\n# weighted avg       0.79      0.80      0.78    431040","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:43:30.478419Z","iopub.execute_input":"2021-07-16T07:43:30.478731Z","iopub.status.idle":"2021-07-16T07:43:30.489589Z","shell.execute_reply.started":"2021-07-16T07:43:30.478693Z","shell.execute_reply":"2021-07-16T07:43:30.488496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGB Classifer","metadata":{}},{"cell_type":"code","source":"xgb_clf = xgboost.XGBClassifier()\n\n#Output\n# Training Accuracy XGBClassifier 0.8285155171573801\n# F1-Score for Training XGBClassifier 0.8190635931663616\n# Classification Report for Training               precision    recall  f1-score   support\n\n#            1       0.76      0.70      0.73     16834\n#            2       0.86      0.93      0.89   1247437\n#            3       0.73      0.57      0.64    388821\n#            4       0.69      0.42      0.52     71064\n\n#     accuracy                           0.83   1724156\n#    macro avg       0.76      0.66      0.70   1724156\n# weighted avg       0.82      0.83      0.82   1724156\n\n# Validation Accuracy XGBClassifier 0.824072011878248\n# F1-Score for Validation XGBClassifier 0.8143256111124326\n# Classification Report for Validation               precision    recall  f1-score   support\n\n#            1       0.74      0.67      0.70      4209\n#            2       0.85      0.93      0.89    311860\n#            3       0.72      0.56      0.63     97205\n#            4       0.66      0.41      0.50     17766\n\n#     accuracy                           0.82    431040\n#    macro avg       0.74      0.64      0.68    431040\n# weighted avg       0.81      0.82      0.81    431040","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:43:30.490923Z","iopub.execute_input":"2021-07-16T07:43:30.491237Z","iopub.status.idle":"2021-07-16T07:43:30.505434Z","shell.execute_reply.started":"2021-07-16T07:43:30.491208Z","shell.execute_reply":"2021-07-16T07:43:30.504346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ada Boost Classifier","metadata":{}},{"cell_type":"code","source":"adab_clf = AdaBoostClassifier()\n\n#Output\n# Training Accuracy AdaBoostClassifier 0.7255921157946265\n# F1-Score for Training AdaBoostClassifier 0.6823642127666705\n# Classification Report for Training               precision    recall  f1-score   support\n\n#            1       0.37      0.07      0.12     16834\n#            2       0.76      0.93      0.83   1247437\n#            3       0.52      0.22      0.31    388821\n#            4       0.25      0.13      0.17     71064\n\n#     accuracy                           0.73   1724156\n#    macro avg       0.48      0.34      0.36   1724156\n# weighted avg       0.68      0.73      0.68   1724156\n\n# Validation Accuracy AdaBoostClassifier 0.7255939123979213\n# F1-Score for Validation AdaBoostClassifier 0.6824048586340324\n# Classification Report for Validation               precision    recall  f1-score   support\n\n#            1       0.41      0.08      0.13      4209\n#            2       0.76      0.93      0.83    311860\n#            3       0.52      0.22      0.31     97205\n#            4       0.25      0.13      0.17     17766\n\n#     accuracy                           0.73    431040\n#    macro avg       0.48      0.34      0.36    431040\n# weighted avg       0.68      0.73      0.68    431040","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:43:30.509583Z","iopub.execute_input":"2021-07-16T07:43:30.510157Z","iopub.status.idle":"2021-07-16T07:43:30.521699Z","shell.execute_reply.started":"2021-07-16T07:43:30.509955Z","shell.execute_reply":"2021-07-16T07:43:30.520573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gradient Boosting Classifier","metadata":{}},{"cell_type":"code","source":"gb_clf = GradientBoostingClassifier()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:43:30.52323Z","iopub.execute_input":"2021-07-16T07:43:30.523545Z","iopub.status.idle":"2021-07-16T07:43:30.538378Z","shell.execute_reply.started":"2021-07-16T07:43:30.523518Z","shell.execute_reply":"2021-07-16T07:43:30.537325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Voting Classifier","metadata":{}},{"cell_type":"code","source":"voting_clf = VotingClassifier(\n    estimators=[('rf', rnf_clf), ('xgb_clf', xgb_clf)], n_jobs=2\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:43:45.038884Z","iopub.execute_input":"2021-07-16T07:43:45.039453Z","iopub.status.idle":"2021-07-16T07:43:45.04462Z","shell.execute_reply.started":"2021-07-16T07:43:45.039402Z","shell.execute_reply":"2021-07-16T07:43:45.043827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split = StratifiedShuffleSplit(n_splits=1, test_size = 0.2, random_state = 21)\nX_train = X_valid = 0\nfor train_index, valid_index in split.split(train, train[\"Severity\"]):\n    X_train = train.iloc[train_index]\n    X_valid = train.iloc[valid_index]\n\ny_train = X_train['Severity'].copy()\nX_train.drop([\"Severity\"], axis = 1, inplace = True)\ny_valid = X_valid['Severity'].copy()\nX_valid.drop([\"Severity\"], axis = 1, inplace = True)\n\nvoting_clf.fit(X_train,y_train)\ny_pred = voting_clf.predict(X_train)\ny_valid_pred = voting_clf.predict(X_valid)\nprint(\"Training Accuracy\", voting_clf.__class__.__name__, accuracy_score(y_train, y_pred))\nprint(\"F1-Score for Training\", voting_clf.__class__.__name__, f1_score(y_train, y_pred, average=\"weighted\"))\nprint(\"Classification Report for Training\", classification_report(y_train, y_pred))\nprint(\"Validation Accuracy\", voting_clf.__class__.__name__, accuracy_score(y_valid, y_valid_pred))\nprint(\"F1-Score for Validation\", voting_clf.__class__.__name__, f1_score(y_valid, y_valid_pred, average=\"weighted\"))\nprint(\"Classification Report for Validation\", classification_report(y_valid, y_valid_pred))\n    \n# for clf in (xgb):\n#     clf.fit(X_train,y_train)\n#     y_pred = clf.predict(X_train)\n#     y_valid_pred = clf.predict(X_valid)\n#     print(\"Training Accuracy\", clf.__class__.__name__, accuracy_score(y_train, y_pred))\n#     print(\"F1-Score for Training\", clf.__class__.__name__, f1_score(y_train, y_pred, average=\"weighted\"))\n#     print(\"Classification Report for Training\", clf.__class__.__name__, classification_report(y_train, y_pred))\n#     print(\"Validation Accuracy\", clf.__class__.__name__, accuracy_score(y_valid, y_valid_pred))\n#     print(\"F1-Score for Validation\", clf.__class__.__name__, f1_score(y_valid, y_valid_pred, average=\"weighted\"))\n#     print(\"Classification Report for Validation\", clf.__class__.__name__, classification_report(y_valid, y_valid_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:43:47.628724Z","iopub.execute_input":"2021-07-16T07:43:47.629092Z","iopub.status.idle":"2021-07-16T09:20:36.690043Z","shell.execute_reply.started":"2021-07-16T07:43:47.629048Z","shell.execute_reply":"2021-07-16T09:20:36.684224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# voting_clf.fit(X_train,y_train)\n# y_pred = voting_clf.predict(X_train)\n# y_valid_pred = voting_clf.predict(X_valid)\n# print(\"Training Accuracy\", voting_clf.__class__.__name__, accuracy_score(y_train, y_pred))\n# print(\"F1-Score for Training\", voting_clf.__class__.__name__, f1_score(y_train, y_pred, average=\"weighted\"))\n# print(\"Classification Report for Training\", classification_report(y_train, y_pred))\n# print(\"Validation Accuracy\", voting_clf.__class__.__name__, accuracy_score(y_valid, y_valid_pred))\n# print(\"F1-Score for Validation\", voting_clf.__class__.__name__, f1_score(y_valid, y_valid_pred, average=\"weighted\"))\n# print(\"Classification Report for Validation\", classification_report(y_valid, y_valid_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:43:30.553184Z","iopub.status.idle":"2021-07-16T07:43:30.554008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# param_distribs = {\n#     'n_estimators': randint(low=200, high=300),\n#     'max_features': randint(low=30, high=60),\n#     'max_depth':randint(low=185, high = 205)\n# }\n\n# forest_clf = RandomForestClassifier(random_state=21)\n# forest_clf_search = RandomizedSearchCV(forest_clf, param_distributions=param_distribs, n_jobs = 2, return_train_score = True,\n#                                 n_iter=5, cv=2, random_state=21)\n# forest_clf_search.fit(X_train,y_train)\n\n# print(forest_clf_search.best_params_)\n# print(forest_clf_search.best_score_)\n# pd.DataFrame(forest_clf_search.cv_results_)\n\n# {'max_depth': 192, 'max_features': 29, 'n_estimators': 211}\n# 0.8422375933500217","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:43:30.555111Z","iopub.status.idle":"2021-07-16T07:43:30.555913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}